{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import importlib\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "# deprecated in torch_geometric 2.0\n",
    "try:\n",
    "    from torch_geometric.loader import DataLoader\n",
    "except:\n",
    "    from torch_geometric.data import DataLoader\n",
    "\n",
    "import hydragnn\n",
    "\n",
    "import voronoi_utils as voronoi_utils\n",
    "importlib.reload(voronoi_utils)\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "#torch.use_deterministic_algorithms(True)\n",
    "dataset = voronoi_utils.VoronoiNet(root='.',force_reload=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = torch.tensor([319,  12,  81, 137, 351,  34, 103, 258, 322, 118, 307, 252, 284, 293,\n",
    "        163, 291,  21, 201, 312, 187, 349, 246, 235, 203, 101,  83, 194, 129,\n",
    "        133, 272, 158, 124, 317, 268,  37, 172,  14, 162, 105, 113, 279, 354,\n",
    "          8, 393, 170,  52, 396,  86, 374, 225,   6, 372, 238,  44, 224,  19,\n",
    "        320,  54, 237, 245, 115, 278, 242, 205, 303, 357,  41, 256, 298, 375,\n",
    "        220,  65, 111,  94, 324, 292, 335, 161,  95, 380, 151, 202, 346, 231,\n",
    "        149, 325, 333, 119,  42,  99, 106, 207, 355, 330, 184, 281, 146, 232,\n",
    "          3, 369, 306, 261, 344, 358, 204, 387, 309, 211,  63, 222, 361, 301,\n",
    "        260, 288, 345,  46,   9, 388, 155,  64, 153, 247, 191,  61,  36, 287,\n",
    "        255, 141, 316, 348, 125, 399,  70, 311,  53,  38,  15, 304, 365,  32,\n",
    "         10, 290, 336, 159,  79, 389, 223, 285,  20, 126, 264, 175, 193, 167,\n",
    "        107, 171, 244, 189, 134,  91, 283, 179, 318, 230,  39,  25, 112,  59,\n",
    "         11, 152, 249, 366, 228, 371, 182, 381, 394, 132, 385, 343, 271, 254,\n",
    "         78, 305, 367, 282, 377, 362,  48, 120, 337, 160, 145,  97,  23,  77,\n",
    "        199, 379,  87, 269, 263, 192, 378,  50, 323, 174, 350,  71,  93, 262,\n",
    "        383, 259, 123,  85, 390, 135, 314, 164,  28, 190,  26, 294,  45, 173,\n",
    "        197,   1, 110,  31, 215, 275, 327, 143, 116, 217, 154, 328, 196, 214,\n",
    "         67, 286,   5,  96, 178, 165, 136, 313, 347,   7,  76, 157, 310, 382,\n",
    "         74,  75,  90, 195, 156, 329, 338,  49,  68, 121, 176, 359, 188, 186,\n",
    "        147,  92, 169,  47, 257, 168, 243, 297,  89, 138, 239,   2,  84, 114,\n",
    "        332, 180, 397, 208,  66, 300, 128,  18, 229, 295, 226, 331,  29, 276,\n",
    "        227, 251, 392, 117, 360,  55, 221,  17, 148, 363, 206,  40, 209, 341,\n",
    "        100,  57, 364, 368, 108, 308,  27, 373, 386,  62, 102, 236,  98, 200,\n",
    "        130, 342, 289, 166, 321,  16, 139, 270, 240, 280, 150, 127,  33,  22,\n",
    "         82, 233, 198, 241,  73, 299, 250, 326,  88, 266, 109, 273,  56,  35,\n",
    "         30, 177, 210, 356,  58, 185, 144, 140, 265,  80, 183,  51,   0,   4,\n",
    "         69, 104, 181,  72, 218, 142, 395, 296, 253,  60, 340, 353, 398, 339,\n",
    "         24, 219, 277, 315, 352, 370, 376, 391, 274, 234, 131, 248, 334, 216,\n",
    "        122, 213,  43, 384, 212,  13, 302, 267])\n",
    "shuffled_dataset = dataset.index_select(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed data parallel: nccl master at 127.0.0.1:8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:8890 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to Hamilton.utk.tennessee.edu:8890 (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n"
     ]
    },
    {
     "ename": "DistNetworkError",
     "evalue": "The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:8890 (errno: 98 - Address already in use). The server socket has failed to bind to Hamilton.utk.tennessee.edu:8890 (errno: 98 - Address already in use).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m var_config \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mNeuralNetwork\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mVariables_of_interest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Always initialize for multi-rank training.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m world_size, world_rank \u001b[39m=\u001b[39m hydragnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49msetup_ddp()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m log_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mactivation_func/128x10_sigmoid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Enable print to log file.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/HydraGNN/hydragnn/utils/distributed.py:166\u001b[0m, in \u001b[0;36msetup_ddp\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m    161\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDistributed data parallel: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m master at \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m             \u001b[39m%\u001b[39m (backend, master_addr, master_port),\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dist\u001b[39m.\u001b[39mis_initialized():\n\u001b[0;32m--> 166\u001b[0m         dist\u001b[39m.\u001b[39;49minit_process_group(\n\u001b[1;32m    167\u001b[0m             backend\u001b[39m=\u001b[39;49mbackend, init_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39menv://\u001b[39;49m\u001b[39m\"\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimedelta(seconds\u001b[39m=\u001b[39;49m\u001b[39m1800\u001b[39;49m)\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDDP has to be initialized within a job - Running in sequential mode\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:86\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     85\u001b[0m     t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime_ns()\n\u001b[0;32m---> 86\u001b[0m     func_return \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     87\u001b[0m     time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime_ns() \u001b[39m-\u001b[39m t1\n\u001b[1;32m     89\u001b[0m     msg_dict \u001b[39m=\u001b[39m _get_msg_dict(func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1177\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mif\u001b[39;00m store \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1174\u001b[0m     rendezvous_iterator \u001b[39m=\u001b[39m rendezvous(\n\u001b[1;32m   1175\u001b[0m         init_method, rank, world_size, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m     store, rank, world_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(rendezvous_iterator)\n\u001b[1;32m   1178\u001b[0m     store\u001b[39m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1180\u001b[0m     \u001b[39m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/distributed/rendezvous.py:246\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m master_port \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(_get_env_or_raise(\u001b[39m\"\u001b[39m\u001b[39mMASTER_PORT\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    244\u001b[0m use_libuv \u001b[39m=\u001b[39m query_dict\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39muse_libuv\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mUSE_LIBUV\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 246\u001b[0m store \u001b[39m=\u001b[39m _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n\u001b[1;32m    248\u001b[0m \u001b[39myield\u001b[39;00m (store, rank, world_size)\n\u001b[1;32m    250\u001b[0m \u001b[39m# If this configuration is invalidated, there is nothing we can do about it\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/distributed/rendezvous.py:174\u001b[0m, in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout, use_libuv)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     start_daemon \u001b[39m=\u001b[39m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m TCPStore(\n\u001b[1;32m    175\u001b[0m         hostname, port, world_size, start_daemon, timeout, multi_tenant\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, use_libuv\u001b[39m=\u001b[39;49muse_libuv\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mDistNetworkError\u001b[0m: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:8890 (errno: 98 - Address already in use). The server socket has failed to bind to Hamilton.utk.tennessee.edu:8890 (errno: 98 - Address already in use)."
     ]
    }
   ],
   "source": [
    "# Set this path for output.\n",
    "try:\n",
    "    os.environ[\"SERIALIZED_DATA_PATH\"]\n",
    "except:\n",
    "    os.environ[\"SERIALIZED_DATA_PATH\"] = os.getcwd()\n",
    "\n",
    "# num_samples = 64\n",
    "\n",
    "# Configurable run choices (JSON file that accompanies this example script).\n",
    "#filename = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"qm9.json\")\n",
    "\n",
    "# filename = os.path.join(os.getcwd(), \"voronoi_PNA.json\")\n",
    "filename = os.path.join(os.getcwd(), \"voronoi_pna_activation_func.json\")\n",
    "with open(filename, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "verbosity = config[\"Verbosity\"][\"level\"]\n",
    "var_config = config[\"NeuralNetwork\"][\"Variables_of_interest\"]\n",
    "\n",
    "# Always initialize for multi-rank training.\n",
    "world_size, world_rank = hydragnn.utils.setup_ddp()\n",
    "\n",
    "log_name = \"activation_func/128x10_sigmoid\"\n",
    "# Enable print to log file.\n",
    "hydragnn.utils.setup_log(log_name)\n",
    "\n",
    "# Use built-in torch_geometric dataset.\n",
    "# Filter function above used to run quick example.\n",
    "# NOTE: data is moved to the device in the pre-transform.\n",
    "# NOTE: transforms/filters will NOT be re-run unless the qm9/processed/ directory is removed.\n",
    "\n",
    "# dataset = torch_geometric.datasets.QM9(\n",
    "#     root=\"dataset/qm9\", pre_transform=qm9_pre_transform, pre_filter=qm9_pre_filter\n",
    "# )\n",
    "train, val, test = hydragnn.preprocess.split_dataset(\n",
    "    shuffled_dataset, config[\"NeuralNetwork\"][\"Training\"][\"perc_train\"], False\n",
    ")\n",
    "(train_loader, val_loader, test_loader,) = hydragnn.preprocess.create_dataloaders(\n",
    "    train, val, test, config[\"NeuralNetwork\"][\"Training\"][\"batch_size\"]\n",
    ")\n",
    "\n",
    "config = hydragnn.utils.update_config(config, train_loader, val_loader, test_loader)\n",
    "\n",
    "model = hydragnn.models.create_model_config(\n",
    "    config=config[\"NeuralNetwork\"],\n",
    "    verbosity=verbosity,\n",
    ")\n",
    "model = hydragnn.utils.get_distributed_model(model, verbosity)\n",
    "\n",
    "learning_rate = config[\"NeuralNetwork\"][\"Training\"][\"Optimizer\"][\"learning_rate\"]\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=0.000001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m writer \u001b[39m=\u001b[39m hydragnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mget_summary_writer(log_name)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m hydragnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39msave_config(config, log_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m hydragnn\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mtrain_validate_test(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     model,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     train_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     val_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     test_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     writer,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     scheduler,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     config[\u001b[39m\"\u001b[39;49m\u001b[39mNeuralNetwork\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     log_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     verbosity,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     create_plots\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mVisualization\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mcreate_plots\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ecalisk1/git/HydraGNN/examples/voronoi_composite/pna/voronoi_pna_pytorch2.2.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m )\n",
      "File \u001b[0;32m~/git/HydraGNN/hydragnn/train/train_validate_test.py:113\u001b[0m, in \u001b[0;36mtrain_validate_test\u001b[0;34m(model, optimizer, train_loader, val_loader, test_loader, writer, scheduler, config, model_with_config_name, verbosity, plot_init_solution, plot_hist_solution, create_plots)\u001b[0m\n\u001b[1;32m    110\u001b[0m     visualizer\u001b[39m.\u001b[39mnum_nodes_plot()\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m create_plots \u001b[39mand\u001b[39;00m plot_init_solution:  \u001b[39m# visualizing of initial conditions\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     _, _, true_values, predicted_values \u001b[39m=\u001b[39m test(test_loader, model, verbosity)\n\u001b[1;32m    114\u001b[0m     visualizer\u001b[39m.\u001b[39mcreate_scatter_plots(\n\u001b[1;32m    115\u001b[0m         true_values,\n\u001b[1;32m    116\u001b[0m         predicted_values,\n\u001b[1;32m    117\u001b[0m         output_names\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mVariables_of_interest\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39moutput_names\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    118\u001b[0m         iepoch\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m profiler \u001b[39m=\u001b[39m Profiler(\u001b[39m\"\u001b[39m\u001b[39m./logs/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_with_config_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/git/HydraGNN/hydragnn/train/train_validate_test.py:564\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader, model, verbosity, reduce_ranks, return_samples)\u001b[0m\n\u001b[1;32m    562\u001b[0m head_index \u001b[39m=\u001b[39m get_head_indices(model, data)\n\u001b[1;32m    563\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(get_device())\n\u001b[0;32m--> 564\u001b[0m pred \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m    565\u001b[0m error, tasks_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mloss(pred, data\u001b[39m.\u001b[39my, head_index)\n\u001b[1;32m    566\u001b[0m \u001b[39m## FIXME: temporary\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1523\u001b[0m, in \u001b[0;36mDistributedDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mDistributedDataParallel.forward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1519\u001b[0m     inputs, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_forward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1520\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[1;32m   1521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delay_all_reduce_all_params\n\u001b[0;32m-> 1523\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_ddp_forward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_forward(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1359\u001b[0m, in \u001b[0;36mDistributedDataParallel._run_ddp_forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_ddp_forward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1358\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inside_ddp_forward():\n\u001b[0;32m-> 1359\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py312gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/HydraGNN/hydragnn/models/Base.py:289\u001b[0m, in \u001b[0;36mBase.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m conv, feat_layer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_convs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_layers):\n\u001b[1;32m    288\u001b[0m     c, pos \u001b[39m=\u001b[39m conv(x\u001b[39m=\u001b[39mx, pos\u001b[39m=\u001b[39mpos, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconv_args)\n\u001b[0;32m--> 289\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation_function(feat_layer(c))\n\u001b[1;32m    291\u001b[0m \u001b[39m#### multi-head decoder part####\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# shared dense layers for graph level output\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mbatch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Run training with the given model and Voronoi dataset.\n",
    "writer = hydragnn.utils.get_summary_writer(log_name)\n",
    "hydragnn.utils.save_config(config, log_name)\n",
    "\n",
    "hydragnn.train.train_validate_test(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    writer,\n",
    "    scheduler,\n",
    "    config[\"NeuralNetwork\"],\n",
    "    log_name,\n",
    "    verbosity,\n",
    "    create_plots=config[\"Visualization\"][\"create_plots\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Last updated: Tue Jun 11 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.2\n",
      "IPython version      : 8.25.0\n",
      "\n",
      "Compiler    : GCC 12.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.146.1-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 56\n",
      "Architecture: 64bit\n",
      "\n",
      "Git repo: git@github.com:erdemcaliskan/HydraGNN.git\n",
      "\n",
      "matplotlib     : 3.8.4\n",
      "torch          : 2.2.2\n",
      "torch_geometric: 2.5.2\n",
      "json           : 2.0.9\n",
      "hydragnn       : 3.0rc1\n",
      "networkx       : 3.1\n",
      "numpy          : 1.26.4\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -r -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [2]])\n",
      "tensor([[True],\n",
      "        [True],\n",
      "        [True]])\n",
      "tensor([[0.4340],\n",
      "        [0.4585],\n",
      "        [0.4585]])\n",
      "tensor([[0.4340],\n",
      "        [0.4585],\n",
      "        [0.4585]])\n",
      "torch: 2.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "idx1 = torch.tensor([[1], [2], [2]])\n",
    "print(idx1)\n",
    "idx2 = torch.tensor([[1, 2, 2]]).t()\n",
    "print(idx2)\n",
    "print(idx1 ==idx2)\n",
    "# idx1 and idx2 are the same but the output results are different. Why?\n",
    "\n",
    "a = torch.tensor([[0.6280, 0.5672, 0.3760],\n",
    "                  [0.4340, 0.9902, 0.1539],\n",
    "                  [0.4585, 0.2638, 0.6983]])\n",
    "\n",
    "print(a.gather(0, idx1))\n",
    "print(a.gather(0, idx2))\n",
    "%watermark -p torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
